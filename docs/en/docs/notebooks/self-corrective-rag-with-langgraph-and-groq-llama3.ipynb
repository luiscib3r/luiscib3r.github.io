{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='flex gap-1 items-center'>\n",
    "    <img alt='self llama' src='../images/self-rag.jpeg' width='128' height='128' class='rounded'>\n",
    "    <h1>Self Corrective RAG with LangGraph and Groq Llama 3</h1>\n",
    "</div>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-core langchain-community langchain-groq langgraph wikipedia\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain_community.retrievers import WikipediaRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG Components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you! How can I assist you today?\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    model='llama3-groq-8b-8192-tool-use-preview'\n",
    ")\n",
    "\n",
    "res = llm.invoke('Hi! How are you today?')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Meta AI',\n",
       " 'summary': 'Meta AI is an American company owned by Meta (formerly Facebook) that develops artificial intelligence and augmented and artificial reality technologies. Meta AI deems itself an academic research laboratory, focused on generating knowledge for the AI community, and should not be confused with Meta\\'s Applied Machine Learning (AML) team, which focuses on the practical applications of its products. \\n\\nThe laboratory was founded as Facebook Artificial Intelligence Research (FAIR) with locations at the headquarters in Menlo Park, California, London, United Kingdom, and a new laboratory in Manhattan. FAIR was officially announced in September 2013. FAIR was first directed by New York University\\'s Yann LeCun, a deep learning professor and Turing Award winner. Working with NYU\\'s Center for Data Science, FAIR\\'s initial goal was to research data science, machine learning, and artificial intelligence and to \"understand intelligence, to discover its fundamental principles, and to make machines significantly more intelligent\". Research at FAIR pioneered the technology that led to face recognition, tagging in photographs, and personalized feed recommendation. Vladimir Vapnik, a pioneer in statistical learning, joined FAIR in 2014. Vapnik is the co-inventor of the support-vector machine and one of the developers of the Vapnik–Chervonenkis theory.\\nFAIR opened a research center in Paris, France in 2015, and subsequently launched smaller satellite research labs in Seattle, Pittsburgh, Tel Aviv, Montreal and London. In 2016, FAIR partnered with Google, Amazon, IBM, and Microsoft in creating the Partnership on Artificial Intelligence to Benefit People and Society, an organization with a focus on open licensed research, supporting ethical and efficient research practices, and discussing fairness, inclusivity, and transparency.\\nIn 2018, Jérôme Pesenti, former CTO of IBM\\'s big data group, assumed the role of president of FAIR, while LeCun stepped down to serve as chief AI scientist. In 2018, FAIR was placed 25th in the AI Research Rankings 2019, which ranked the top global organizations leading AI research. FAIR quickly rose to eighth position in 2019, and maintained eighth position in the 2020 rank. FAIR had approximately 200 staff in 2018, and had the goal to double that number by 2020.\\nFAIR\\'s initial work included research in learning-model enabled memory networks, self-supervised learning and generative adversarial networks, text classification and translation, as well as computer vision. FAIR released Torch deep-learning modules as well as PyTorch in 2017, an open-source machine learning framework, which was subsequently used in several deep learning technologies, such as Tesla\\'s autopilot  and Uber\\'s Pyro. Also in 2017, FAIR discontinued a research project once AI bots developed a language that was unintelligible to humans, inciting conversations about dystopian fear of artificial intelligence going out of control. However, FAIR clarified that the research had been shut down because they had accomplished their initial goal to understand how languages are generated, rather than out of fear.\\nFAIR was renamed Meta AI following the rebranding that changed Facebook, Inc. to Meta Platforms Inc.\\nIn 2022, Meta AI predicted the 3D shape of 600 million potential proteins in two weeks.\\n\\nArtificial intelligence communication requires a machine to understand natural language and to generate language that is natural. Meta AI seeks to improve these technologies to improve safe communication regardless of what language the user might speak. Thus, a central task involves the generalization of natural language processing (NLP) technology to other languages. As such, Meta AI actively works on unsupervised machine translation. Meta AI seeks to improve natural-language interfaces by developing aspects of chitchat dialogue such as repetition, specificity, response-relatedness and question-asking, incorporating personality into image captioning, and generating creativity-based language.\\n\\nIn February 2023, Meta AI launched LLaMA (Large Language Model Meta AI), a large language model ranging from 7B to 65B parameters.\\n\\nUntil 2022, Meta AI mainly used CPU and in-house custom chip as hardware, before finally switching to Nvidia GPU. This necessitated a complete redesign of several data centers, since they needed 24 to 32 times the networking capacity and new liquid cooling systems.\\n\\nThe MTIA v1 is Meta\\'s first-generation AI training and inference accelerator, developed specifically for Meta\\'s recommendation workloads. It was fabricated using TSMC\\'s 7 nm process technology and operates at a frequency of 800 MHz. In terms of processing power, the accelerator provides 102.4 TOPS at INT8 precision and 51.2 TFLOPS at FP16 precision, while maintaining a thermal design power (TDP) of 25 W.\\nMeta AI offers options for users to customize their interaction with its features. Users are able to mute the AI chatbot on platforms like Facebook, Instagram, and WhatsApp, temporarily halting notifications from the chatbot. Some platforms also offer the ability to hide certain AI elements from their interface. To locate the relevant settings, users can consult the platform\\'s help documentation or settings menu.\\nConcerns\\nSince May 2024, the Meta AI chatbot has summarized news from various outlets without linking directly to original articles, including in Canada, where news links are banned on its platforms. This use of news content without compensation has raised ethical and legal concerns, especially as Meta continues to reduce news visibility on its platforms.\\n\\nMeta Platforms\\n\\nCircleOut. \"How Meta AI Impacts Our Lives\". Retrieved 2024-07-06.\\n\\nOfficial website',\n",
       " 'source': 'https://en.wikipedia.org/wiki/Meta_AI'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = WikipediaRetriever(top_k_results=6)\n",
    "\n",
    "docs = retriever.invoke(\"Meta AI\")\n",
    "\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta AI is an American company owned by Meta (formerly Facebook) that develops artificial intelligence and augmented and artificial reality technologies. Meta AI deems itself an academic research laboratory, focused on generating knowledge for the AI community, and should not be confused with Meta's Applied Machine Learning (AML) team, which focuses on the practical applications of its products. \n",
      "\n",
      "The laboratory was founded as Facebook Artificial Intelligence Research (FAIR) with locations at the headquarters in Menlo Park, California, London, United Kingdom, and a new laboratory in Manhattan. FAIR was officially announced in September 2013. FAIR was first directed by New York University's Yann LeCun, a deep learning professor and Turing Award winner. Working with NYU's Center for Data Science, FAIR's initial goal was to research data science, machine learning, and artificial intelligence and to \"understand intelligence, to discover its fundamental principles, and to make machines significantly more intelligent\". Research at FAIR pioneered the technology that led to face recognition, tagging in photographs, and personalized feed recommendation. Vladimir Vapnik, a pioneer in statistical learning, joined FAIR in 2014. Vapnik is the co-inventor of the support-vector machine and one of the developers of the Vapnik–Chervonenkis theory.\n",
      "FAIR opened a research center in Paris, France in 2015, and subsequently launched smaller satellite research labs in Seattle, Pittsburgh, Tel Aviv, Montreal and London. In 2016, FAIR partnered with Google, Amazon, IBM, and Microsoft in creating the Partnership on Artificial Intelligence to Benefit People and Society, an organization with a focus on open licensed research, supporting ethical and efficient research practices, and discussing fairness, inclusivity, and transparency.\n",
      "In 2018, Jérôme Pesenti, former CTO of IBM's big data group, assumed the role of president of FAIR, while LeCun stepped down to serve as chief AI scientist. In 2018, FAIR was placed 25th in the AI Research Rankings 2019, which ranked the top global organizations leading AI research. FAIR quickly rose to eighth position in 2019, and maintained eighth position in the 2020 rank. FAIR had approximately 200 staff in 2018, and had the goal to double that number by 2020.\n",
      "FAIR's initial work included research in learning-model enabled memory networks, self-supervised learning and generative adversarial networks, text classification and translation, as well as computer vision. FAIR released Torch deep-learning modules as well as PyTorch in 2017, an open-source machine learning framework, which was subsequently used in several deep learning technologies, such as Tesla's autopilot  and Uber's Pyro. Also in 2017, FAIR discontinued a research project once AI bots developed a language that was unintelligible to humans, inciting conversations about dystopian fear of artificial intelligence going out of control. However, FAIR clarified that the research had been shut down because they had accomplished their initial goal to understand how languages are generated, rather than out of fear.\n",
      "FAIR was renamed Meta AI following the rebranding that changed Facebook, Inc. to Meta Platforms Inc.\n",
      "In 2022, Meta AI predicted the 3D shape of 600 million potential proteins in two weeks.\n",
      "\n",
      "Artificial intelligence communication requires a machine to understand natural language and to generate language that is natural. Meta AI seeks to improve these technologies to improve safe communication regardless of what language the user might speak. Thus, a central task involves the generalization of natural language processing (NLP) technology to other languages. As such, Meta AI actively works on unsupervised machine translation. Meta AI seeks to improve natural-language interfaces by developing aspects of chitchat dialogue such as repetition, specificity, response-relatedness and question-asking, incorporating personality into image captioning, and generating creati\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs: list[Document]) -> str:\n",
    "    formatted = [\n",
    "        (\n",
    "            f\"Source ID: {i+1}\\n\"\n",
    "            f\"Article Title: {doc.metadata['title']}\\n\"\n",
    "            f\"Article URL: {doc.metadata['source']}\\n\"\n",
    "            f\"Article Content: {doc.page_content}\"\n",
    "        )\n",
    "        for i, doc in enumerate(docs)\n",
    "    ]\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Source ID: 1\n",
      "Article Title: Meta AI\n",
      "Article URL: https://en.wikipedia.org/wiki/Meta_AI\n",
      "Article Content: Meta AI is an American company owned by Meta (formerly Facebook) that develops artificial intelligence and augmented and artificial reality technologies. Meta AI deems itself an academic research laboratory, focused on generating knowledge for the AI community, and should not be confused with Meta's Applied Machine Learning (AML) team, which focuses on the practical applications of its products. \n",
      "\n",
      "The laboratory was founded as Facebook Artificial Intelligence Research (FAIR) with locations at the headquarters in Menlo Park, California, London, United Kingdom, and a new laboratory in Manhattan. FAIR was officially announced in September 2013. FAIR was first directed by New York University's Yann LeCun, a deep learning professor and Turing Award winner. Working with NYU's Center for Data Science, FAIR's initial goal was to research data science, machine learning, and artificial intelligence and to \"understand intelligence, to discover its fundamental principles, and to make machines significantly more intelligent\". Research at FAIR pioneered the technology that led to face recognition, tagging in photographs, and personalized feed recommendation. Vladimir Vapnik, a pioneer in statistical learning, joined FAIR in 2014. Vapnik is the co-inventor of the support-vector machine and one of the developers of the Vapnik–Chervonenkis theory.\n",
      "FAIR opened a research center in Paris, France in 2015, and subsequently launched smaller satellite research labs in Seattle, Pittsburgh, Tel Aviv, Montreal and London. In 2016, FAIR partnered with Google, Amazon, IBM, and Microsoft in creating the Partnership on Artificial Intelligence to Benefit People and Society, an organization with a focus on open licensed research, supporting ethical and efficient research practices, and discussing fairness, inclusivity, and transparency.\n",
      "In 2018, Jérôme Pesenti, former CTO of IBM's big data group, assumed the role of president of FAIR, while LeCun stepped down to serve as chief AI scientist. In 2018, FAIR was placed 25th in the AI Research Rankings 2019, which ranked the top global organizations leading AI research. FAIR quickly rose to eighth position in 2019, and maintained eighth position in the 2020 rank. FAIR had approximately 200 staff in 2018, and had the goal to double that number by 2020.\n",
      "FAIR's initial work included research in learning-model enabled memory networks, self-supervised learning and generative adversarial networks, text classification and translation, as well as computer vision. FAIR released Torch deep-learning modules as well as PyTorch in 2017, an open-source machine learning framework, which was subsequently used in several deep learning technologies, such as Tesla's autopilot  and Uber's Pyro. Also in 2017, FAIR discontinued a research project once AI bots developed a language that was unintelligible to humans, inciting conversations about dystopian fear of artificial intelligence going out of control. However, FAIR clarified that the research had been shut down because they had accomplished their initial goal to understand how languages are generated, rather than out of fear.\n",
      "FAIR was renamed Meta AI following the rebranding that changed Facebook, Inc. to Meta Platforms Inc.\n",
      "In 2022, Meta AI predicted the 3D shape of 600 million potential proteins in two weeks.\n",
      "\n",
      "Artificial intelligence communication requires a machine to understand natural language and to generate language that is natural. Meta AI seeks to improve these technologies to improve safe communication regardless of what language the user might speak. Thus, a central task involves the generalization of natural language processing (NLP) technology to other languages. As such, Meta AI actively works on unsupervised machine translation. Meta AI seeks to improve natural-language interfaces by developing aspects of chitchat dialogue such as repetition, specificity, response-relatedness and question-asking, incorporating personality into image captioning, and generating creati\n",
      "\n",
      "Source ID: 2\n",
      "Article Title: Llama (language model)\n",
      "Article URL: https://en.wikipedia.org/wiki/Llama_(language_model)\n",
      "Article Content: Llama (acronym for Large Language Model Meta AI, and formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.1, released in July 2024.\n",
      "Model weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the model were shared via BitTorrent. In response, Meta AI issued DMCA takedown requests against repositories sharing the link on GitHub. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Llama models are trained at different parameter sizes, ranging between 7B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\n",
      "Alongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.\n",
      "\n",
      "After the release of large language models such as GPT-3, a focus of research was up-scaling models which in some instances showed major increases in emergent capabilities. The release of ChatGPT and its surprise success caused an increase in attention to large language models.\n",
      "Compared with other responses to ChatGPT, Meta's Chief AI scientist Yann LeCun stated that large language models are best for aiding with writing.\n",
      "\n",
      "LLaMA was announced on February 24, 2023, via a blog post and a paper describing the model's training, architecture, and performance. The inference code used to run the model was publicly released under the open-source GPLv3 license. Access to the model's weights was managed by an application process, with access to be granted \"on a case-by-case basis to academic researchers; those affiliated with organizations in government, civil society, and academia; and industry research laboratories around the world\".\n",
      "Llama was trained on only publicly available information, and was trained at various different model sizes, with the intention to make it more accessible to different hardware.\n",
      "Meta AI reported the 13B parameter model performance on most NLP benchmarks exceeded that of the much larger GPT-3 (with 175B parameters), and the largest 65B model was competitive with state of the art models such as PaLM and Chinchilla.\n",
      "\n",
      "On March 3, 2023, a torrent containing LLaMA's weights was uploaded, with a link to the torrent shared on the 4chan imageboard and subsequently spread through online AI communities. That same day, a pull request on the main LLaMA repository was opened, requesting to add the magnet link to the official documentation. On March 4, a pull request was opened to add links to HuggingFace repositories containing the model. On March 6, Meta filed takedown requests to remove the HuggingFace repositories linked in the pull request, characterizing it as \"unauthorized distribution\" of the model. HuggingFace complied with the requests. On March 20, Meta filed a DMCA takedown request for copyright infringement against a repository containing a script that downloaded LLaMA from a mirror, and GitHub complied the next day.\n",
      "Reactions to the leak varied. Some speculated that the model would be used for malicious purposes, such as more sophisticated spam. Some have celebrated the model's accessibility, as well as the fact that smaller versions of the model can be run relatively cheaply, suggesting that this will promote the flourishing of additional research developments. Multiple commentators, such as Simon Willison, compared LLaMA to Stable Diffusion, a text-to-image model which, unlike comparably sophisticated models which preceded it, was openly distributed, leading to a rapid proliferation of associated tools, techniques, and software.\n",
      "\n",
      "On July 18, 2023, in partnership with Microsoft, Meta announ\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(docs[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer question with citations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CitedAnswer Output Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitedAnswer(BaseModel):\n",
    "    \"\"\"Answer the user question based only on the given sources, and cite the sources used.\"\"\"\n",
    "\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"The answer to the user question, which is based only on the given sources.\",\n",
    "    )\n",
    "    citations: list[int] = Field(\n",
    "        ...,\n",
    "        description=\"The integer IDs of the SPECIFIC sources which justify the answer.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful AI assistant. Your task is to answer questions based SOLELY on the information provided in the given articles.\n",
      "\n",
      "Main instructions:\n",
      "1. Answer the user's question using ONLY the information from the provided articles.\n",
      "2. Cite the source for EVERY statement you make, using the format [source_id] at the end of each sentence.\n",
      "3. If the information needed to answer the question is not in the provided articles, respond: \"I don't have enough information in the provided sources to answer this question.\"\n",
      "4. DO NOT use external knowledge or information not in the given articles, even if you believe it to be correct.\n",
      "5. If you can only partially answer the question, provide the information you have and then indicate that the rest of the question cannot be answered with the available information.\n",
      "6. Be concise and direct in your responses.\n",
      "\n",
      "Reference articles:\n",
      "\u001b[33;1m\u001b[1;3m{documents}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RAG_SYSTEM_PROMPT = (\n",
    "    \"You are a helpful AI assistant. Your task is to answer questions based SOLELY on the information provided in the given articles.\\n\\n\"\n",
    "    \"Main instructions:\\n\"\n",
    "    \"1. Answer the user's question using ONLY the information from the provided articles.\\n\"\n",
    "    \"2. Cite the source for EVERY statement you make, using the format [source_id] at the end of each sentence.\\n\"\n",
    "    \"3. If the information needed to answer the question is not in the provided articles, respond: \\\"I don't have enough information in the provided sources to answer this question.\\\"\\n\"\n",
    "    \"4. DO NOT use external knowledge or information not in the given articles, even if you believe it to be correct.\\n\"\n",
    "    \"5. If you can only partially answer the question, provide the information you have and then indicate that the rest of the question cannot be answered with the available information.\\n\"\n",
    "    \"6. Be concise and direct in your responses.\\n\\n\"\n",
    "    \"Reference articles:\\n\"\n",
    "    \"{documents}\\n\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "RAG_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", RAG_SYSTEM_PROMPT),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "RAG_PROMPT.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG Chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_llm = llm.with_structured_output(CitedAnswer)\n",
    "\n",
    "rag_response_chain = (\n",
    "    RunnablePassthrough.assign(documents=(\n",
    "        lambda x: format_docs(x[\"documents\"]))\n",
    "    )\n",
    "    | RAG_PROMPT\n",
    "    | rag_llm\n",
    ")\n",
    "\n",
    "retrieve_docs = (lambda x: x['question']) | retriever\n",
    "\n",
    "rag_chain = RunnablePassthrough.assign(\n",
    "    documents=retrieve_docs).assign(response=rag_response_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CitedAnswer(answer='Meta AI is an American company owned by Meta (formerly Facebook) that develops artificial intelligence and augmented and artificial reality technologies.', citations=[1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rag_chain.invoke({\"question\": \"What is Meta AI?\"})\n",
    "\n",
    "result['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CitedAnswer(answer='Jann LeCun is a French computer scientist and director of AI Research at Facebook. He is also a professor at New York University and is known for his work on convolutional neural networks and his role in the development of the LeNet-5 and LeNet-7 algorithms.', citations=[1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rag_chain.invoke({\"question\": \"Who is Jann LeCun?\"})\n",
    "\n",
    "result['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luisciber-buq1kKJR-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
